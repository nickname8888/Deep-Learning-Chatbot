{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nickname8888/deep_learning_chatbot/blob/main/small_messaging_chatbot_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk4JqfZW09z3",
        "outputId": "ae3898d3-d23c-4a7d-9bfc-9ae4b2407f5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-29 15:09:33--  http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
            "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9916637 (9.5M) [application/zip]\n",
            "Saving to: ‘cornell_movie_dialogs_corpus.zip’\n",
            "\n",
            "cornell_movie_dialo 100%[===================>]   9.46M  25.1MB/s    in 0.4s    \n",
            "\n",
            "2022-04-29 15:09:34 (25.1 MB/s) - ‘cornell_movie_dialogs_corpus.zip’ saved [9916637/9916637]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPAn8u7k1Uq3",
        "outputId": "8910ad7e-dfeb-4c3a-ae52-8fa42c9431e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/cornell_movie_dialogs_corpus.zip\n",
            "   creating: /content/data/cornell movie-dialogs corpus/\n",
            "  inflating: /content/data/cornell movie-dialogs corpus/.DS_Store  \n",
            "   creating: /content/data/__MACOSX/\n",
            "   creating: /content/data/__MACOSX/cornell movie-dialogs corpus/\n",
            "  inflating: /content/data/__MACOSX/cornell movie-dialogs corpus/._.DS_Store  \n",
            "  inflating: /content/data/cornell movie-dialogs corpus/chameleons.pdf  \n",
            "  inflating: /content/data/__MACOSX/cornell movie-dialogs corpus/._chameleons.pdf  \n",
            "  inflating: /content/data/cornell movie-dialogs corpus/movie_characters_metadata.txt  \n",
            "  inflating: /content/data/cornell movie-dialogs corpus/movie_conversations.txt  \n",
            "  inflating: /content/data/cornell movie-dialogs corpus/movie_lines.txt  \n",
            "  inflating: /content/data/cornell movie-dialogs corpus/movie_titles_metadata.txt  \n",
            "  inflating: /content/data/cornell movie-dialogs corpus/raw_script_urls.txt  \n",
            "  inflating: /content/data/cornell movie-dialogs corpus/README.txt  \n",
            "  inflating: /content/data/__MACOSX/cornell movie-dialogs corpus/._README.txt  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/cornell_movie_dialogs_corpus.zip -d /content/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KACYXQtG12Va",
        "outputId": "44167945-e5c9-4f15-c2f6-df4f814423ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\", \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\", \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\", \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\", \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\", \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L271', 'L272', 'L273', 'L274', 'L275']\", \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L276', 'L277']\", \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L280', 'L281']\", \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L363', 'L364']\", \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L365', 'L366']\"]\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "lines = open('/content/data/cornell movie-dialogs corpus/movie_lines.txt', encoding='utf-8',\n",
        "             errors='ignore').read().split('\\n')\n",
        "\n",
        "convers = open('/content/data/cornell movie-dialogs corpus/movie_conversations.txt', encoding='utf-8',\n",
        "             errors='ignore').read().split('\\n')\n",
        "\n",
        "print(convers[:10])\n",
        "# print(covers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WIOFP_LW2adO"
      },
      "outputs": [],
      "source": [
        "exchn = []\n",
        "for conver in convers:\n",
        "    exchn.append(conver.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \" \").replace(\",\",\"\").split())\n",
        "\n",
        "diag = {}\n",
        "for line in lines:\n",
        "    diag[line.split(' +++$+++ ')[0]] = line.split(' +++$+++ ')[-1]\n",
        "\n",
        "## delete\n",
        "del(lines, convers, conver, line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRMNUUUm2jcV",
        "outputId": "e140f81d-ce85-42d5-bfee-bc03833dcfd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'L1045': 'They do not!', 'L1044': 'They do to!', 'L985': 'I hope so.', 'L984': 'She okay?', 'L925': \"Let's go.\", 'L924': 'Wow', 'L872': \"Okay -- you're gonna need to learn how to lie.\", 'L871': 'No', 'L870': 'I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?', 'L869': 'Like my fear of wearing pastels?'}\n"
          ]
        }
      ],
      "source": [
        "# print(exchn[:10])\n",
        "print({k: diag[k] for k in list(diag)[:10]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3vl1Lz93Tab",
        "outputId": "c259efee-6072-4146-b576-d8bae527f21d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.', \"Well, I thought we'd start with pronunciation, if that's okay with you.\", 'Not the hacking and gagging and spitting part.  Please.', \"You're asking me out.  That's so cute. What's your name again?\", \"No, no, it's my fault -- we didn't have a proper introduction ---\", 'Cameron.', \"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\", 'Why?', 'Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.', 'Gosh, if only we could find Kat a boyfriend...']\n",
            "[\"Well, I thought we'd start with pronunciation, if that's okay with you.\", 'Not the hacking and gagging and spitting part.  Please.', \"Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\", 'Forget it.', 'Cameron.', \"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\", 'Seems like she could get a date easy enough...', 'Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.', \"That's a shame.\", 'Let me see what I can do.']\n"
          ]
        }
      ],
      "source": [
        "questions = []\n",
        "answers = []\n",
        "\n",
        "for conver in exchn:\n",
        "    for i in range(len(conver) - 1):\n",
        "        questions.append(diag[conver[i]])\n",
        "        answers.append(diag[conver[i+1]])\n",
        "\n",
        "## delete\n",
        "del(diag, exchn, conver, i)\n",
        "\n",
        "print(questions[:10])\n",
        "print(answers[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDSymGmP3iri",
        "outputId": "77a35944-cf28-4783-f3ff-64dcaa4c322c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Cameron.', 'Why?', 'There.', 'Sure have.', 'Hi.', 'I was?', 'Well, no...', 'But', 'What crap?', 'No']\n",
            "[\"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\", 'Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.', 'Where?', \"I really, really, really wanna go, but I can't.  Not unless my sister goes.\", 'Looks like things worked out tonight, huh?', \"You never wanted to go out with 'me, did you?\", \"Then that's all you had to say.\", 'You always been this selfish?', \"Me.  This endless ...blonde babble. I'm like, boring myself.\", \"Okay -- you're gonna need to learn how to lie.\"]\n"
          ]
        }
      ],
      "source": [
        "sorted_ques = []\n",
        "sorted_ans = []\n",
        "for i in range(len(questions)):\n",
        "    if len(questions[i]) < 13:\n",
        "        sorted_ques.append(questions[i])\n",
        "        sorted_ans.append(answers[i])\n",
        "\n",
        "print(sorted_ques[:10])\n",
        "print(sorted_ans[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oF0stF0v3vvv"
      },
      "outputs": [],
      "source": [
        "def clean_text(txt):\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(r\"i'm\", \"i am\", txt)\n",
        "    txt = re.sub(r\"he's\", \"he is\", txt)\n",
        "    txt = re.sub(r\"she's\", \"she is\", txt)\n",
        "    txt = re.sub(r\"that's\", \"that is\", txt)\n",
        "    txt = re.sub(r\"what's\", \"what is\", txt)\n",
        "    txt = re.sub(r\"where's\", \"where is\", txt)\n",
        "    txt = re.sub(r\"\\'ll\", \" will\", txt)\n",
        "    txt = re.sub(r\"\\'ve\", \" have\", txt)\n",
        "    txt = re.sub(r\"\\'re\", \" are\", txt)\n",
        "    txt = re.sub(r\"\\'d\", \" would\", txt)\n",
        "    txt = re.sub(r\"won't\", \"will not\", txt)\n",
        "    txt = re.sub(r\"can't\", \"can not\", txt)\n",
        "    txt = re.sub(r\"[^\\w\\s]\", \"\", txt)\n",
        "    return txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ql1a4C0U32-S"
      },
      "outputs": [],
      "source": [
        "clean_ques = []\n",
        "clean_ans = []\n",
        "\n",
        "for line in sorted_ques:\n",
        "    clean_ques.append(clean_text(line))\n",
        "        \n",
        "for line in sorted_ans:\n",
        "    clean_ans.append(clean_text(line))\n",
        "\n",
        "## delete\n",
        "del(answers, questions, line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W1k7mFm4NSi",
        "outputId": "3f232949-6ece-4896-e872-ba62cd34d7d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cameron', 'why', 'there', 'sure have', 'hi', 'i was', 'well no', 'but', 'what crap', 'no']\n",
            "['the thing is cameron  i am at the mercy of a particularly hideous breed of loser  my sister  i can not date until she does', 'unsolved mystery  she used to be really popular when she started high school then it was just like she got sick of it or something', 'where', 'i really really really wanna go but i can not  not unless my sister goes', 'looks like things worked out tonight huh', 'you never wanted to go out with me did you', 'then that is all you had to say', 'you always been this selfish', 'me  this endless blonde babble i am like boring myself', 'okay  you are gonna need to learn how to lie']\n"
          ]
        }
      ],
      "source": [
        "print(clean_ques[:10])\n",
        "print(clean_ans[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQshxzBu4A5p",
        "outputId": "5d8387d9-dc2d-4730-cfa3-42303003e8d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the thing is cameron i am at the mercy of a', 'unsolved mystery she used to be really popular when she started', 'where', 'i really really really wanna go but i can not not', 'looks like things worked out tonight huh', 'you never wanted to go out with me did you', 'then that is all you had to say', 'you always been this selfish', 'me this endless blonde babble i am like boring myself', 'okay you are gonna need to learn how to lie']\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(clean_ans)):\n",
        "    clean_ans[i] = ' '.join(clean_ans[i].split()[:11])\n",
        "\n",
        "del(sorted_ans, sorted_ques)\n",
        "print(clean_ans[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EWwyFugj4ZkE"
      },
      "outputs": [],
      "source": [
        "## trimming\n",
        "clean_ans=clean_ans[:30000]\n",
        "clean_ques=clean_ques[:30000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "U_CIYOHd4dqU"
      },
      "outputs": [],
      "source": [
        "word2count = {}\n",
        "\n",
        "for line in clean_ques:\n",
        "    for word in line.split():\n",
        "        if word not in word2count:\n",
        "            word2count[word] = 1\n",
        "        else:\n",
        "            word2count[word] += 1\n",
        "for line in clean_ans:\n",
        "    for word in line.split():\n",
        "        if word not in word2count:\n",
        "            word2count[word] = 1\n",
        "        else:\n",
        "            word2count[word] += 1\n",
        "\n",
        "## delete\n",
        "del(word, line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7fZE1END4kSx"
      },
      "outputs": [],
      "source": [
        "thresh = 5\n",
        "\n",
        "vocab = {}\n",
        "word_num = 0\n",
        "for word, count in word2count.items():\n",
        "    if count >= thresh:\n",
        "        vocab[word] = word_num\n",
        "        word_num += 1\n",
        "        \n",
        "## delete\n",
        "del(word2count, word, count, thresh)       \n",
        "del(word_num)        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzbLFawp4o93",
        "outputId": "0b21352e-e083-4fc6-f0d9-43c7aec8b02f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cameron': 0, 'why': 1, 'there': 2, 'sure': 3, 'have': 4, 'hi': 5, 'i': 6, 'was': 7, 'well': 8, 'no': 9}\n"
          ]
        }
      ],
      "source": [
        "print({k: vocab[k] for k in list(vocab)[:10]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NefV4KCg7jg9"
      },
      "outputs": [],
      "source": [
        "for i in range(len(clean_ans)):\n",
        "    clean_ans[i] = '<SOS> ' + clean_ans[i] + ' <EOS>'\n",
        "\n",
        "tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n",
        "x = len(vocab)\n",
        "for token in tokens:\n",
        "    vocab[token] = x\n",
        "    x += 1\n",
        "  \n",
        "vocab['cameron'] = vocab['<PAD>']\n",
        "vocab['<PAD>'] = 0\n",
        "\n",
        "## delete\n",
        "del(token, tokens) \n",
        "del(x)\n",
        "\n",
        "### inv answers dict ###\n",
        "inv_vocab = {w:v for v, w in vocab.items()}\n",
        "\n",
        "## delete\n",
        "del(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "iL0RJI-47nyb"
      },
      "outputs": [],
      "source": [
        "encoder_inp = []\n",
        "for line in clean_ques:\n",
        "    lst = []\n",
        "    for word in line.split():\n",
        "        if word not in vocab:\n",
        "            lst.append(vocab['<OUT>'])\n",
        "        else:\n",
        "            lst.append(vocab[word])\n",
        "        \n",
        "    encoder_inp.append(lst)\n",
        "\n",
        "decoder_inp = []\n",
        "for line in clean_ans:\n",
        "    lst = []\n",
        "    for word in line.split():\n",
        "        if word not in vocab:\n",
        "            lst.append(vocab['<OUT>'])\n",
        "        else:\n",
        "            lst.append(vocab[word])        \n",
        "    decoder_inp.append(lst)\n",
        "\n",
        "### delete\n",
        "del(clean_ans, clean_ques, line, lst, word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq-fEKqAdK8M",
        "outputId": "bcf237c3-bda5-444a-d4a5-48d604d5bce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3023], [1], [2], [3, 4], [5], [6, 7], [8, 9], [10], [11, 12], [9]]\n",
            "[[3026, 60, 524, 28, 3023, 6, 40, 280, 60, 3025, 68, 87, 3024], [3026, 3025, 938, 14, 1042, 18, 227, 125, 2234, 70, 14, 2235, 3024], [3026, 151, 3024], [3026, 6, 125, 125, 125, 1035, 31, 10, 6, 235, 29, 29, 3024], [3026, 1482, 364, 883, 986, 35, 105, 64, 3024], [3026, 47, 33, 1133, 18, 31, 35, 207, 50, 110, 47, 3024], [3026, 84, 27, 28, 146, 47, 760, 18, 73, 3024], [3026, 47, 811, 1253, 46, 3025, 3024], [3026, 50, 46, 3025, 1510, 3025, 6, 40, 364, 1401, 504, 3024], [3026, 15, 47, 82, 2098, 1322, 18, 1845, 59, 18, 780, 3024]]\n"
          ]
        }
      ],
      "source": [
        "print(encoder_inp[:10])\n",
        "print(decoder_inp[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9pEbZmjK7sAv"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "encoder_inp = pad_sequences(encoder_inp, 13, padding='post', truncating='post')\n",
        "decoder_inp = pad_sequences(decoder_inp, 13, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "l9xVq5N77wWi"
      },
      "outputs": [],
      "source": [
        "decoder_final_output = []\n",
        "for i in decoder_inp:\n",
        "    decoder_final_output.append(i[1:]) \n",
        "\n",
        "decoder_final_output = pad_sequences(decoder_final_output, 13, padding='post', truncating='post')\n",
        "\n",
        "\n",
        "del(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZtcpr1e70S_",
        "outputId": "cd98ccc3-3a49-41de-adfc-35fcd5747fda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30000, 13, 3027)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "decoder_final_output = to_categorical(decoder_final_output, len(vocab))\n",
        "\n",
        "print(decoder_final_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "HfY4j1aB74ic"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input\n",
        "\n",
        "\n",
        "enc_inp = Input(shape=(13, ))\n",
        "dec_inp = Input(shape=(13, ))\n",
        "\n",
        "\n",
        "VOCAB_SIZE = len(vocab)\n",
        "embed = Embedding(VOCAB_SIZE+1, output_dim=50, \n",
        "                  input_length=13,\n",
        "                  trainable=True                  \n",
        "                  )\n",
        "\n",
        "\n",
        "enc_embed = embed(enc_inp)\n",
        "enc_lstm = LSTM(400, return_sequences=True, return_state=True)\n",
        "enc_op, h, c = enc_lstm(enc_embed)\n",
        "enc_states = [h, c]\n",
        "\n",
        "\n",
        "\n",
        "dec_embed = embed(dec_inp)\n",
        "dec_lstm = LSTM(400, return_sequences=True, return_state=True)\n",
        "dec_op, _, _ = dec_lstm(dec_embed, initial_state=enc_states)\n",
        "\n",
        "dense = Dense(VOCAB_SIZE, activation='softmax')\n",
        "\n",
        "dense_op = dense(dec_op)\n",
        "\n",
        "model = Model([enc_inp, dec_inp], dense_op)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "eOGSmyjA8GLD"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',metrics=['acc'],optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaSCaiCL8JG_",
        "outputId": "04bb201b-44a0-4d47-e8e8-08dd8d88cb59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 13)]         0           []                               \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 13)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 13, 50)       151400      ['input_1[0][0]',                \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 13, 400),    721600      ['embedding[0][0]']              \n",
            "                                 (None, 400),                                                     \n",
            "                                 (None, 400)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 13, 400),    721600      ['embedding[1][0]',              \n",
            "                                 (None, 400),                     'lstm[0][1]',                   \n",
            "                                 (None, 400)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 13, 3027)     1213827     ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,808,427\n",
            "Trainable params: 2,808,427\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIMwgyWM8NYi",
        "outputId": "a7f733d8-0fc9-4f08-e714-82d6e94bb9d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "938/938 [==============================] - 36s 30ms/step - loss: 3.1053 - acc: 0.4932\n",
            "Epoch 2/150\n",
            "938/938 [==============================] - 26s 28ms/step - loss: 2.7425 - acc: 0.5319\n",
            "Epoch 3/150\n",
            "938/938 [==============================] - 26s 27ms/step - loss: 2.6090 - acc: 0.5423\n",
            "Epoch 4/150\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 2.5363 - acc: 0.5468\n",
            "Epoch 5/150\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 2.4784 - acc: 0.5505\n",
            "Epoch 6/150\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 2.4300 - acc: 0.5531\n",
            "Epoch 7/150\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 2.3839 - acc: 0.5554\n",
            "Epoch 8/150\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 2.3407 - acc: 0.5578\n",
            "Epoch 9/150\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 2.2966 - acc: 0.5601\n",
            "Epoch 10/150\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 2.2554 - acc: 0.5621\n",
            "Epoch 11/150\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 2.2160 - acc: 0.5638\n",
            "Epoch 12/150\n",
            "938/938 [==============================] - 26s 27ms/step - loss: 2.1743 - acc: 0.5663\n",
            "Epoch 13/150\n",
            "938/938 [==============================] - 26s 27ms/step - loss: 2.1314 - acc: 0.5688\n",
            "Epoch 14/150\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 2.0894 - acc: 0.5720\n",
            "Epoch 15/150\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 2.0480 - acc: 0.5757\n",
            "Epoch 16/150\n",
            "938/938 [==============================] - 25s 26ms/step - loss: 2.0088 - acc: 0.5797\n",
            "Epoch 17/150\n",
            "938/938 [==============================] - 24s 26ms/step - loss: 1.9704 - acc: 0.5838\n",
            "Epoch 18/150\n",
            "938/938 [==============================] - 24s 26ms/step - loss: 1.9331 - acc: 0.5886\n",
            "Epoch 19/150\n",
            "938/938 [==============================] - 23s 25ms/step - loss: 1.8972 - acc: 0.5934\n",
            "Epoch 20/150\n",
            "938/938 [==============================] - 24s 25ms/step - loss: 1.8625 - acc: 0.5986\n",
            "Epoch 21/150\n",
            "938/938 [==============================] - 24s 25ms/step - loss: 1.8282 - acc: 0.6030\n",
            "Epoch 22/150\n",
            "938/938 [==============================] - 24s 25ms/step - loss: 1.7950 - acc: 0.6084\n",
            "Epoch 23/150\n",
            "938/938 [==============================] - 24s 25ms/step - loss: 1.7624 - acc: 0.6141\n",
            "Epoch 24/150\n",
            "938/938 [==============================] - 24s 25ms/step - loss: 1.7309 - acc: 0.6192\n",
            "Epoch 25/150\n",
            "938/938 [==============================] - 24s 26ms/step - loss: 1.6997 - acc: 0.6246\n",
            "Epoch 26/150\n",
            "938/938 [==============================] - 23s 25ms/step - loss: 1.6697 - acc: 0.6298\n",
            "Epoch 27/150\n",
            "938/938 [==============================] - 23s 25ms/step - loss: 1.6402 - acc: 0.6350\n",
            "Epoch 28/150\n",
            "938/938 [==============================] - 24s 25ms/step - loss: 1.6115 - acc: 0.6404\n",
            "Epoch 29/150\n",
            "938/938 [==============================] - 24s 25ms/step - loss: 1.5827 - acc: 0.6452\n",
            "Epoch 30/150\n",
            "938/938 [==============================] - 23s 25ms/step - loss: 1.5545 - acc: 0.6504\n",
            "Epoch 31/150\n",
            "938/938 [==============================] - 23s 25ms/step - loss: 1.5280 - acc: 0.6562\n",
            "Epoch 32/150\n",
            "938/938 [==============================] - 23s 25ms/step - loss: 1.5017 - acc: 0.6616\n",
            "Epoch 33/150\n",
            "938/938 [==============================] - 23s 25ms/step - loss: 1.4757 - acc: 0.6669\n",
            "Epoch 34/150\n",
            "938/938 [==============================] - 23s 24ms/step - loss: 1.4503 - acc: 0.6721\n",
            "Epoch 35/150\n",
            "938/938 [==============================] - 23s 24ms/step - loss: 1.4251 - acc: 0.6765\n",
            "Epoch 36/150\n",
            "938/938 [==============================] - 23s 24ms/step - loss: 1.4010 - acc: 0.6817\n",
            "Epoch 37/150\n",
            "938/938 [==============================] - 23s 24ms/step - loss: 1.3770 - acc: 0.6871\n",
            "Epoch 38/150\n",
            "938/938 [==============================] - 23s 24ms/step - loss: 1.3538 - acc: 0.6916\n",
            "Epoch 39/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 1.3306 - acc: 0.6973\n",
            "Epoch 40/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 1.3076 - acc: 0.7024\n",
            "Epoch 41/150\n",
            "938/938 [==============================] - 23s 24ms/step - loss: 1.2860 - acc: 0.7065\n",
            "Epoch 42/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 1.2642 - acc: 0.7112\n",
            "Epoch 43/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 1.2428 - acc: 0.7159\n",
            "Epoch 44/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 1.2227 - acc: 0.7205\n",
            "Epoch 45/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 1.2023 - acc: 0.7250\n",
            "Epoch 46/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 1.1826 - acc: 0.7291\n",
            "Epoch 47/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 1.1631 - acc: 0.7336\n",
            "Epoch 48/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 1.1443 - acc: 0.7382\n",
            "Epoch 49/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 1.1255 - acc: 0.7425\n",
            "Epoch 50/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 1.1077 - acc: 0.7465\n",
            "Epoch 51/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 1.0900 - acc: 0.7504\n",
            "Epoch 52/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 1.0739 - acc: 0.7542\n",
            "Epoch 53/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 1.0572 - acc: 0.7579\n",
            "Epoch 54/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 1.0404 - acc: 0.7620\n",
            "Epoch 55/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 1.0245 - acc: 0.7656\n",
            "Epoch 56/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 1.0090 - acc: 0.7696\n",
            "Epoch 57/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.9941 - acc: 0.7728\n",
            "Epoch 58/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.9793 - acc: 0.7761\n",
            "Epoch 59/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.9648 - acc: 0.7800\n",
            "Epoch 60/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.9505 - acc: 0.7834\n",
            "Epoch 61/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.9375 - acc: 0.7866\n",
            "Epoch 62/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.9242 - acc: 0.7894\n",
            "Epoch 63/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.9109 - acc: 0.7927\n",
            "Epoch 64/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.8998 - acc: 0.7948\n",
            "Epoch 65/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.8865 - acc: 0.7983\n",
            "Epoch 66/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.8749 - acc: 0.8010\n",
            "Epoch 67/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.8634 - acc: 0.8038\n",
            "Epoch 68/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.8533 - acc: 0.8056\n",
            "Epoch 69/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.8429 - acc: 0.8080\n",
            "Epoch 70/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.8306 - acc: 0.8116\n",
            "Epoch 71/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.8203 - acc: 0.8138\n",
            "Epoch 72/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.8113 - acc: 0.8154\n",
            "Epoch 73/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.8008 - acc: 0.8175\n",
            "Epoch 74/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.7912 - acc: 0.8207\n",
            "Epoch 75/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.7818 - acc: 0.8229\n",
            "Epoch 76/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.7729 - acc: 0.8243\n",
            "Epoch 77/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.7643 - acc: 0.8265\n",
            "Epoch 78/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.7569 - acc: 0.8282\n",
            "Epoch 79/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.7473 - acc: 0.8305\n",
            "Epoch 80/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.7402 - acc: 0.8321\n",
            "Epoch 81/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.7319 - acc: 0.8345\n",
            "Epoch 82/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.7242 - acc: 0.8357\n",
            "Epoch 83/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.7162 - acc: 0.8380\n",
            "Epoch 84/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.7085 - acc: 0.8399\n",
            "Epoch 85/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.7044 - acc: 0.8407\n",
            "Epoch 86/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.6949 - acc: 0.8429\n",
            "Epoch 87/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.6884 - acc: 0.8441\n",
            "Epoch 88/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.6827 - acc: 0.8452\n",
            "Epoch 89/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.6788 - acc: 0.8461\n",
            "Epoch 90/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.6701 - acc: 0.8487\n",
            "Epoch 91/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.6642 - acc: 0.8497\n",
            "Epoch 92/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.6588 - acc: 0.8508\n",
            "Epoch 93/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.6540 - acc: 0.8517\n",
            "Epoch 94/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.6479 - acc: 0.8536\n",
            "Epoch 95/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.6436 - acc: 0.8540\n",
            "Epoch 96/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.6370 - acc: 0.8559\n",
            "Epoch 97/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.6321 - acc: 0.8570\n",
            "Epoch 98/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.6311 - acc: 0.8561\n",
            "Epoch 99/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.6206 - acc: 0.8593\n",
            "Epoch 100/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.6187 - acc: 0.8599\n",
            "Epoch 101/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.6137 - acc: 0.8610\n",
            "Epoch 102/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.6104 - acc: 0.8610\n",
            "Epoch 103/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.6068 - acc: 0.8619\n",
            "Epoch 104/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.6000 - acc: 0.8634\n",
            "Epoch 105/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.5966 - acc: 0.8644\n",
            "Epoch 106/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.5939 - acc: 0.8646\n",
            "Epoch 107/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.5914 - acc: 0.8652\n",
            "Epoch 108/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.5856 - acc: 0.8669\n",
            "Epoch 109/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.5821 - acc: 0.8673\n",
            "Epoch 110/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.5789 - acc: 0.8682\n",
            "Epoch 111/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.5765 - acc: 0.8684\n",
            "Epoch 112/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.5715 - acc: 0.8694\n",
            "Epoch 113/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.5713 - acc: 0.8692\n",
            "Epoch 114/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.5644 - acc: 0.8712\n",
            "Epoch 115/150\n",
            "938/938 [==============================] - 23s 25ms/step - loss: 0.5636 - acc: 0.8708\n",
            "Epoch 116/150\n",
            "938/938 [==============================] - 23s 25ms/step - loss: 0.5600 - acc: 0.8713\n",
            "Epoch 117/150\n",
            "938/938 [==============================] - 23s 24ms/step - loss: 0.5582 - acc: 0.8721\n",
            "Epoch 118/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.5553 - acc: 0.8726\n",
            "Epoch 119/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.5512 - acc: 0.8734\n",
            "Epoch 120/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.5465 - acc: 0.8748\n",
            "Epoch 121/150\n",
            "938/938 [==============================] - 23s 24ms/step - loss: 0.5475 - acc: 0.8741\n",
            "Epoch 122/150\n",
            "938/938 [==============================] - 23s 24ms/step - loss: 0.5457 - acc: 0.8739\n",
            "Epoch 123/150\n",
            "938/938 [==============================] - 24s 26ms/step - loss: 0.5388 - acc: 0.8762\n",
            "Epoch 124/150\n",
            "938/938 [==============================] - 24s 26ms/step - loss: 0.5365 - acc: 0.8767\n",
            "Epoch 125/150\n",
            "938/938 [==============================] - 24s 26ms/step - loss: 0.5366 - acc: 0.8760\n",
            "Epoch 126/150\n",
            "938/938 [==============================] - 24s 25ms/step - loss: 0.5366 - acc: 0.8757\n",
            "Epoch 127/150\n",
            "938/938 [==============================] - 24s 26ms/step - loss: 0.5347 - acc: 0.8759\n",
            "Epoch 128/150\n",
            "938/938 [==============================] - 24s 25ms/step - loss: 0.5258 - acc: 0.8785\n",
            "Epoch 129/150\n",
            "938/938 [==============================] - 24s 25ms/step - loss: 0.5227 - acc: 0.8792\n",
            "Epoch 130/150\n",
            "938/938 [==============================] - 23s 24ms/step - loss: 0.5266 - acc: 0.8780\n",
            "Epoch 131/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.5247 - acc: 0.8778\n",
            "Epoch 132/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.5195 - acc: 0.8797\n",
            "Epoch 133/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.5136 - acc: 0.8812\n",
            "Epoch 134/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.5196 - acc: 0.8791\n",
            "Epoch 135/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.5205 - acc: 0.8781\n",
            "Epoch 136/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.5112 - acc: 0.8810\n",
            "Epoch 137/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.5074 - acc: 0.8817\n",
            "Epoch 138/150\n",
            "938/938 [==============================] - 23s 25ms/step - loss: 0.5089 - acc: 0.8816\n",
            "Epoch 139/150\n",
            "938/938 [==============================] - 23s 25ms/step - loss: 0.5067 - acc: 0.8819\n",
            "Epoch 140/150\n",
            "938/938 [==============================] - 24s 26ms/step - loss: 0.5064 - acc: 0.8819\n",
            "Epoch 141/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.5057 - acc: 0.8817\n",
            "Epoch 142/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.4990 - acc: 0.8834\n",
            "Epoch 143/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.5008 - acc: 0.8827\n",
            "Epoch 144/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.5015 - acc: 0.8821\n",
            "Epoch 145/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.4987 - acc: 0.8827\n",
            "Epoch 146/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.4937 - acc: 0.8842\n",
            "Epoch 147/150\n",
            "938/938 [==============================] - 22s 23ms/step - loss: 0.4952 - acc: 0.8838\n",
            "Epoch 148/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.4930 - acc: 0.8839\n",
            "Epoch 149/150\n",
            "938/938 [==============================] - 22s 24ms/step - loss: 0.4921 - acc: 0.8840\n",
            "Epoch 150/150\n",
            "938/938 [==============================] - 23s 24ms/step - loss: 0.4907 - acc: 0.8842\n"
          ]
        }
      ],
      "source": [
        "history = model.fit([encoder_inp, decoder_inp],decoder_final_output,epochs=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "etWf1ouA9-ED"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "\n",
        "enc_model = Model([enc_inp], enc_states)\n",
        "\n",
        "\n",
        "\n",
        "# decoder Model\n",
        "decoder_state_input_h = Input(shape=(400,))\n",
        "decoder_state_input_c = Input(shape=(400,))\n",
        "\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "\n",
        "decoder_outputs, state_h, state_c = dec_lstm(dec_embed , \n",
        "                                    initial_state=decoder_states_inputs)\n",
        "\n",
        "\n",
        "decoder_states = [state_h, state_c]\n",
        "\n",
        "\n",
        "dec_model = Model([dec_inp]+ decoder_states_inputs,\n",
        "                                      [decoder_outputs]+ decoder_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "eeIsSRnnOhkm"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "LnSXLnPpOfeA",
        "outputId": "a2f3c901-8a83-4ae7-d731-9c90c05fe242"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<built-in method keys of dict object at 0x7ff1af5234b0>\n"
          ]
        }
      ],
      "source": [
        "# # summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "# plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# # summarize history for loss\n",
        "# plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "# plt.title('model loss')\n",
        "# plt.ylabel('loss')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'test'], loc='upper left')\n",
        "# plt.show()\n",
        "\n",
        "print(history.history.keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "vG_Ulxnf-CVs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b9e2eb6-d9c0-432a-ae33-5f50c1397ff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##########################################\n",
            "#       start chatting ver. 1.0          #\n",
            "##########################################\n",
            "you : hi\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input KerasTensor(type_spec=TensorSpec(shape=(None, 13), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 13) for input KerasTensor(type_spec=TensorSpec(shape=(None, 13), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 1).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chatbot :  hi \n",
            "==============================================\n",
            "you : do you work?\n",
            "chatbot :  i volunteer i read to blind people one day a week \n",
            "==============================================\n",
            "you : do you like coffee?\n",
            "chatbot :  <OUT> <OUT> on the load \n",
            "==============================================\n",
            "you : q\n",
            "chatbot :  <OUT> \n",
            "==============================================\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "print(\"##########################################\")\n",
        "print(\"#       start chatting ver. 1.0          #\")\n",
        "print(\"##########################################\")\n",
        "\n",
        "\n",
        "prepro1 = \"\"\n",
        "while prepro1 != 'q':\n",
        "    prepro1  = input(\"you : \")\n",
        "    ## prepro1 = \"Hello\"\n",
        "\n",
        "    prepro1 = clean_text(prepro1)\n",
        "    ## prepro1 = \"hello\"\n",
        "\n",
        "    prepro = [prepro1]\n",
        "    ## prepro1 = [\"hello\"]\n",
        "\n",
        "    txt = []\n",
        "    for x in prepro:\n",
        "        # x = \"hello\"\n",
        "        lst = []\n",
        "        for y in x.split():\n",
        "            ## y = \"hello\"\n",
        "            try:\n",
        "                lst.append(vocab[y])\n",
        "                ## vocab['hello'] = 454\n",
        "            except:\n",
        "                lst.append(vocab['<OUT>'])\n",
        "        txt.append(lst)\n",
        "\n",
        "    ## txt = [[454]]\n",
        "    txt = pad_sequences(txt, 13, padding='post')\n",
        "\n",
        "    ## txt = [[454,0,0,0,.........13]]\n",
        "\n",
        "    stat = enc_model.predict( txt )\n",
        "\n",
        "    empty_target_seq = np.zeros( ( 1 , 1) )\n",
        "     ##   empty_target_seq = [0]\n",
        "\n",
        "\n",
        "    empty_target_seq[0, 0] = vocab['<SOS>']\n",
        "    ##    empty_target_seq = [255]\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_translation = ''\n",
        "\n",
        "    while not stop_condition :\n",
        "\n",
        "        dec_outputs , h, c= dec_model.predict([ empty_target_seq] + stat )\n",
        "        decoder_concat_input = dense(dec_outputs)\n",
        "        ## decoder_concat_input = [0.1, 0.2, .4, .0, ...............]\n",
        "\n",
        "        sampled_word_index = np.argmax( decoder_concat_input[0, -1, :] )\n",
        "        ## sampled_word_index = [2]\n",
        "\n",
        "        sampled_word = inv_vocab[sampled_word_index] + ' '\n",
        "\n",
        "        ## inv_vocab[2] = 'hi'\n",
        "        ## sampled_word = 'hi '\n",
        "\n",
        "        if sampled_word != '<EOS> ':\n",
        "            decoded_translation += sampled_word  \n",
        "\n",
        "        if sampled_word == '<EOS> ' or len(decoded_translation.split()) > 13:\n",
        "            stop_condition = True \n",
        "\n",
        "        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
        "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
        "        ## <SOS> - > hi\n",
        "        ## hi --> <EOS>\n",
        "        stat = [h, c]  \n",
        "\n",
        "    print(\"chatbot : \", decoded_translation )\n",
        "    print(\"==============================================\")  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "small_messaging_chatbot (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1tqyGqKtLOzm43wIpCnNIPDLV3McTJ5r3",
      "authorship_tag": "ABX9TyNuGesItWMiZO0N9q0Q6n9G",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}